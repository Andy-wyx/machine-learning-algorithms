{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85303a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda list #conda install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b0a6144",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A simple example for Reinforcement Learning using table lookup Q-learning method.\n",
    "An agent \"o\" is on the left of a 1 dimensional world, the treasure is on the rightmost location.\n",
    "Run this program and to see how the agent will improve its strategy of finding the treasure.\n",
    "\n",
    "View more on my tutorial page: https://morvanzhou.github.io/tutorials/\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "403d007f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2)  # reproducible\n",
    "# https://numpy.org/doc/stable/reference/random/generated/numpy.random.seed.html\n",
    "#貌似是random.choice因为这个的存在变得reproducible，但是random.uniform还是会正常随机产生\n",
    "\n",
    "# 预设值\n",
    "N_STATES = 6   # the length of the 1 dimensional world 宽度\n",
    "ACTIONS = ['left', 'right']     # available actions\n",
    "EPSILON = 0.9   # greedy 贪婪度 （初期探索阶段，随机更好，不要太greedy）\n",
    "ALPHA = 0.1     # learning rate\n",
    "GAMMA = 0.9    # discount factor\n",
    "MAX_EPISODES = 13   # maximum episodes\n",
    "FRESH_TIME = 0.2    # fresh time for one move 移动间隔时间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8930ca63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define q-table\n",
    "def build_q_table(n_states, actions):\n",
    "    table = pd.DataFrame(\n",
    "        np.zeros((n_states, len(actions))),     # init q-table will 0s (a 6x2 table)\n",
    "        columns=actions,    # actions' name\n",
    "    )\n",
    "    # print(table)    # show table\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3494bc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define how to choose action\n",
    "def choose_action(state, q_table):\n",
    "    state_actions = q_table.iloc[state, :]\n",
    "    # iloc function returns a view of the selected rows and columns from a Pandas DataFrame\n",
    "    if (np.random.uniform() > EPSILON) or ((state_actions == 0).all()):  # act non-greedy or state-action have no value\n",
    "        action_name = np.random.choice(ACTIONS)\n",
    "    else:   # act greedy\n",
    "        action_name = state_actions.idxmax()    # replace argmax to idxmax as argmax means a different function in newer version of pandas\n",
    "    return action_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75e7cca",
   "metadata": {},
   "source": [
    "关于pandas iloc function：\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.iloc.html\n",
    "\n",
    "关于pandas loc function：\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.loc.html\n",
    "\n",
    "关于np.random.uniform及其他常见随机数产生方法：\n",
    "https://www.jianshu.com/p/6c6830deeabb\n",
    "\n",
    "关于np.random.choice（从给定一位数组中随机选取）：\n",
    "https://numpy.org/doc/stable/reference/random/generated/numpy.random.choice.html\n",
    "\n",
    "关于pandas.Series.idxmax():\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.Series.idxmax.html#pandas.Series.idxmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7bb5e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define reward\n",
    "def get_env_feedback(S, A):\n",
    "    # This is how agent will interact with the environment\n",
    "    if A == 'right':    # move right\n",
    "        if S == N_STATES - 2:   # terminate\n",
    "            S_ = 'terminal'\n",
    "            R = 1\n",
    "        else:\n",
    "            S_ = S + 1\n",
    "            R = 0\n",
    "    else:   # move left\n",
    "        R = 0\n",
    "        if S == 0:\n",
    "            S_ = S  # reach the wall\n",
    "        else:\n",
    "            S_ = S - 1\n",
    "    return S_, R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ce6af67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "def update_env(S, episode, step_counter):\n",
    "    # This is how environment be updated\n",
    "    env_list = ['-']*(N_STATES-1) + ['T']   # '---------T' our environment\n",
    "    if S == 'terminal':\n",
    "        interaction = 'Episode %s: total_steps = %s' % (episode+1, step_counter)\n",
    "        print('\\r{}'.format(interaction), end='')\n",
    "        time.sleep(2)\n",
    "        print('\\r                                ', end='')\n",
    "    else:\n",
    "        env_list[S] = 'o'\n",
    "        interaction = ''.join(env_list)\n",
    "        print('\\r{}'.format(interaction), end='')\n",
    "        time.sleep(FRESH_TIME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6433ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rl():\n",
    "    # main part of RL loop\n",
    "    q_table = build_q_table(N_STATES, ACTIONS)\n",
    "    for episode in range(MAX_EPISODES):\n",
    "        step_counter = 0\n",
    "        S = 0\n",
    "        is_terminated = False\n",
    "        update_env(S, episode, step_counter)\n",
    "        while not is_terminated:\n",
    "\n",
    "            A = choose_action(S, q_table)\n",
    "            S_, R = get_env_feedback(S, A)  # take action & get next state and reward\n",
    "            q_predict = q_table.loc[S, A]\n",
    "            if S_ != 'terminal':\n",
    "                q_target = R + GAMMA * q_table.iloc[S_, :].max()   # next state is not terminal\n",
    "            else:\n",
    "                q_target = R     # next state is terminal\n",
    "                is_terminated = True    # terminate this episode\n",
    "\n",
    "            q_table.loc[S, A] += ALPHA * (q_target - q_predict)  # update\n",
    "            S = S_  # move to next state\n",
    "\n",
    "            update_env(S, episode, step_counter+1)\n",
    "            step_counter += 1\n",
    "        print('episode '+str(episode)+'  total steps: '+str(step_counter))\n",
    "        print(q_table)\n",
    "    return q_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ad17f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                episode 0  total steps: 38\n",
      "   left  right\n",
      "0   0.0    0.0\n",
      "1   0.0    0.0\n",
      "2   0.0    0.0\n",
      "3   0.0    0.0\n",
      "4   0.0    0.1\n",
      "5   0.0    0.0\n",
      "                                episode 1  total steps: 22\n",
      "   left  right\n",
      "0   0.0  0.000\n",
      "1   0.0  0.000\n",
      "2   0.0  0.000\n",
      "3   0.0  0.009\n",
      "4   0.0  0.190\n",
      "5   0.0  0.000\n",
      "                                episode 2  total steps: 9\n",
      "   left    right\n",
      "0   0.0  0.00000\n",
      "1   0.0  0.00000\n",
      "2   0.0  0.00081\n",
      "3   0.0  0.02520\n",
      "4   0.0  0.27100\n",
      "5   0.0  0.00000\n",
      "                                episode 3  total steps: 5\n",
      "   left     right\n",
      "0   0.0  0.000000\n",
      "1   0.0  0.000073\n",
      "2   0.0  0.002997\n",
      "3   0.0  0.047070\n",
      "4   0.0  0.343900\n",
      "5   0.0  0.000000\n",
      "                                episode 4  total steps: 7\n",
      "      left     right\n",
      "0  0.00000  0.000007\n",
      "1  0.00000  0.000572\n",
      "2  0.00003  0.006934\n",
      "3  0.00000  0.073314\n",
      "4  0.00000  0.409510\n",
      "5  0.00000  0.000000\n",
      "                                episode 5  total steps: 5\n",
      "      left     right\n",
      "0  0.00000  0.000057\n",
      "1  0.00000  0.001138\n",
      "2  0.00003  0.012839\n",
      "3  0.00000  0.102839\n",
      "4  0.00000  0.468559\n",
      "5  0.00000  0.000000\n",
      "                                episode 6  total steps: 5\n",
      "      left     right\n",
      "0  0.00000  0.000154\n",
      "1  0.00000  0.002180\n",
      "2  0.00003  0.020810\n",
      "3  0.00000  0.134725\n",
      "4  0.00000  0.521703\n",
      "5  0.00000  0.000000\n",
      "                                episode 7  total steps: 5\n",
      "      left     right\n",
      "0  0.00000  0.000335\n",
      "1  0.00000  0.003835\n",
      "2  0.00003  0.030854\n",
      "3  0.00000  0.168206\n",
      "4  0.00000  0.569533\n",
      "5  0.00000  0.000000\n",
      "                                episode 8  total steps: 5\n",
      "      left     right\n",
      "0  0.00000  0.000647\n",
      "1  0.00000  0.006228\n",
      "2  0.00003  0.042907\n",
      "3  0.00000  0.202643\n",
      "4  0.00000  0.612580\n",
      "5  0.00000  0.000000\n",
      "                                episode 9  total steps: 5\n",
      "      left     right\n",
      "0  0.00000  0.001142\n",
      "1  0.00000  0.009467\n",
      "2  0.00003  0.056855\n",
      "3  0.00000  0.237511\n",
      "4  0.00000  0.651322\n",
      "5  0.00000  0.000000\n",
      "                                episode 10  total steps: 5\n",
      "      left     right\n",
      "0  0.00000  0.001880\n",
      "1  0.00000  0.013637\n",
      "2  0.00003  0.072545\n",
      "3  0.00000  0.272379\n",
      "4  0.00000  0.686189\n",
      "5  0.00000  0.000000\n",
      "                                episode 11  total steps: 7\n",
      "       left     right\n",
      "0  0.000000  0.002920\n",
      "1  0.000000  0.018803\n",
      "2  0.000030  0.089805\n",
      "3  0.000000  0.337965\n",
      "4  0.027621  0.717570\n",
      "5  0.000000  0.000000\n",
      "                                episode 12  total steps: 5\n",
      "       left     right\n",
      "0  0.000000  0.004320\n",
      "1  0.000000  0.025005\n",
      "2  0.000030  0.111241\n",
      "3  0.000000  0.368750\n",
      "4  0.027621  0.745813\n",
      "5  0.000000  0.000000\n",
      "\n",
      "Q-table:\n",
      "\n",
      "       left     right\n",
      "0  0.000000  0.004320\n",
      "1  0.000000  0.025005\n",
      "2  0.000030  0.111241\n",
      "3  0.000000  0.368750\n",
      "4  0.027621  0.745813\n",
      "5  0.000000  0.000000\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    q_table = rl()\n",
    "    print('\\r\\nQ-table:\\n')\n",
    "    print(q_table)\n",
    "# -----T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0edf02",
   "metadata": {},
   "source": [
    "例子中的Q（0,left）、Q（1,left）等其实也有value，但是由于episode少而且epsilon=0.9，\n",
    "还没有发生在Q（0，right）被update为非0值后，在state0/state1中采取non-greedy的情况，所以他们很可能依然是0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963a1e2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdaaa86a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e405185",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7401aae4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d551a877",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d640c5c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51109ba7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
